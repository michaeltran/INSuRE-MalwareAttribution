# std imports
import json
import glob
import random
import pickle
import sys

# lib imports
from jsonvectorizer import JsonVectorizer, utils, vectorizers

# user imports
from json_flattener import JsonFlattener

# Globbing directories for compact json strings
data_dir = "../../../data/static_vt/compact/*/*.json"
files = glob.glob(data_dir)

# initializing flattener and doc list
flattener = JsonFlattener()
docs = []
total_files = len(files)
print("\n Reading all Json into memory")

for file in files:
    # Reading each globbed file flattening and appending to docs
    # Output of percentage is shown
    with utils.fopen(file) as f:
        for line in f:
            doc = json.loads(line)
            flat_doc = flattener.flatten_json_iterative_solution(doc)
            docs.append(flat_doc)
    done = int(len(docs) / total_files)
    sys.stdout.write(
        "\r[{}{}] {}%".format(
            "█" * done, "." * (50 - done), int(100 * len(docs) / total_files)
        )
    )
    sys.stdout.flush()

# initializing JsonVectorizer
vectorizer = JsonVectorizer()

# extening vectorizer with flattened_docs
print("\n Extending with docs \n")
for doc in docs:
    vectorizer.extend(doc)
    sys.stdout.write(
        "\r[{}{}] {}%".format(
            "█" * done, "." * (50 - done), int(100 * len(docs) / total_files)
        )
    )
    sys.stdout.flush()


print("\n Now pruning")
# pruning anything that is less that 1%
vectorizer.prune(patterns=["^_"], min_f=0.01)

print("\n Outputting features")
# outputing the feautures learned from the schema
for i, feature_name in enumerate(vectorizer.feature_names_):
    print("{}: {}".format(i, feature_name))


# initializing vectorizers
bool_vectorizer = {"type": "boolean", "vectorizer": vectorizers.BoolVectorizer}
# For numbers, use one-hot encoding with 10 bins
number_vectorizer = {
    "type": "number",
    "vectorizer": vectorizers.NumberVectorizer,
    "kwargs": {"n_bins": 10},
}
# For strings use tokenization, ignoring sparse (<1%) tokens
string_vectosysrizer = {
    "type": "string",
    "vectorizer": vectorizers.StringVectorizer,
    "kwargs": {"min_df": 0.01},
}


# fitting the vectorizer
vectorizers = [bool_vectorizer, number_vectorizer, string_vectorizer]
print("\n Now Fitting")
vectorizer.fit(vectorizers=vectorizers)


# saving the vectorizer to be used later
print("saving the vectorizer as a pickle")
with open("vectorizer_flat.pkl", "w") as f:
    vectorizer = pickle.dump(f)
