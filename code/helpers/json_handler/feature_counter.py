# std imports
import json
import glob
import random
import pickle
import sys
import pandas as pd

# lib imports
from jsonvectorizer import JsonVectorizer, utils, vectorizers

# user imports
from json_flattener import JsonFlattener


'''Globbing directories for compact json strings'''


data_dir = "../../../data/static_vt/compact/*/*.json"
report_type = "virustotal"


'''
data_dir = "../../../data/dynamic_cuckoo/reports/*/*.json"
report_type = "cuckoo"
'''

files = glob.glob(data_dir)

# initializing flattener and doc list
flattener = JsonFlattener()
docs = []
total_files = len(files)
print("\n Reading all JSON into memory")


# getting counts for unique features
master_list = {}

# Reading each globbed file flattening and appending to docs
# Output of percentage is shown
if report_type == "virustotal":

    for file in files:
        with open(file) as f:        
            for line in f:
                doc = json.loads(line)
                flat_doc = flattener.flatten_json_recursive_solution(doc, report_type)
                docs.append(flat_doc)
        done = int(50 * len(docs) / total_files)
        sys.stdout.write(
            "\r[{}{}] {}%".format(
                "█" * done, "." * (50 - done), int(100 * len(docs) / total_files)
            )
        )
        sys.stdout.flush()

    # getting counts for unique features
    for doc in docs:
        for feature in doc:
            if feature in master_list.keys():
                master_list[feature] += 1
            else:
                master_list[feature] = 1

# handle human-readable json
elif report_type == "cuckoo":
    processed = 0
    for file in files:
        with open(file) as f: 
            try:
                doc = json.loads(f.read())
                flat_doc = flattener.flatten_json_recursive_solution(doc, report_type)
                # getting counts for unique features
                for feature in flat_doc:
                    if feature in master_list.keys():
                        master_list[feature] += 1
                    else:
                        master_list[feature] = 1
            except:
                print("\n{} has some invalid bytes in the file\n".format(file))

        processed += 1
        done = int(50 * processed / total_files)
        sys.stdout.write(
            "\r[{}{}] {}%".format(
                "█" * done, "." * (50 - done), int(100 * processed / total_files)
            )
        )
        sys.stdout.flush()


print("\n")
print("{")
for feature, count in master_list.items():
    print("\"{}\": {},".format(feature, count))
print("}")


if report_type == "virustotal":
    save_file = "../../../data/vt_feature_counts.json"
elif report_type == "cuckoo":
    save_file = "../../../data/static_feature_counts.json"

with open(save_file, "w") as f:
    json.dump(master_list, f)
print("Saved to {}".format(save_file))

# df = pd.DataFrame.from_dict(master_list)


