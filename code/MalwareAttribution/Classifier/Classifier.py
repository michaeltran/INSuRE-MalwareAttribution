import numpy as np
from enum import Enum
from sklearn.preprocessing import FunctionTransformer
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import Binarizer
from sklearn.preprocessing import MaxAbsScaler
from sklearn.preprocessing import StandardScaler
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.feature_selection import SelectPercentile
from sklearn.feature_selection import chi2
from sklearn.decomposition import TruncatedSVD
from sklearn.model_selection import GridSearchCV

from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import LinearSVC
from sklearn.ensemble import BaggingClassifier
from sklearn.neural_network import MLPClassifier

from sklearn.pipeline import Pipeline, FeatureUnion

from Classes.ItemSelector import ItemSelector

class Feature(Enum):
    EMBEDDED_DOMAINS_LIST = 1
    TRID = 2
    PE_RESOURCE_LIST = 3
    IMPORTS_LIST = 4
    CONTACTED_URLS_LIST = 5
    SIGNATURES = 101
    BEHAVIOR_CALLS = 102
    BEHAVIOR_DLL_LOADED = 103
    NETWORK_UDP_SRC = 104
    NETWORK_UDP_DST = 105
    NETWORK_HTTP = 106
    NETWORK_HOSTS = 107
    STRINGS = 108

def CustomSpaceTokenizer(doc):
    token = doc.split(' ')
    if '' in token:
        token.remove('')
    return token

def CustomGATokenizer(doc):
    token = doc.split('``')
    if '' in token:
        token.remove('')
    return token

class Classifier(object):

    def BuildClassifierNB(self, training_data_dict, training_data_classification, feature_ids):
        ## Build and Train Model ######################
        classifier = MultinomialNB()

        features = self.GetFeaturesNB(feature_ids)

        final_features = Pipeline([
            ('features', features),
            ('selection', SelectPercentile(chi2, percentile=50)),
        ])

        clf = Pipeline([
            ('features', final_features),
            ('clf', classifier),
        ])

        clf.fit(training_data_dict, training_data_classification)
        ###############################################

        #feats = clf.named_steps['features']
        #test = feats.transform(training_data_dict)
        #print(test[0])

        ## Testing Vectorizer
        #vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 1), tokenizer=CustomSpaceTokenizer, lowercase=True)
        #test = Pipeline([
        #            ('selector', ItemSelector(key='network_udp_src')),
        #            ('vectorizer', vectorizer),
        #        ])
        #X = test.fit_transform(training_data_dict, training_data_classification)
        #feature_names = vectorizer.get_feature_names()
        #print(feature_names)

        return clf

    def BuildClassifierSVM(self, training_data_dict, training_data_classification, feature_ids):
        ## Build and Train Model ######################
        classifier = LinearSVC(max_iter=1000000, C=1)
        #classifier = MLPClassifier(hidden_layer_sizes=(1000,1000,1000), max_iter=1000, n_iter_no_change=10, verbose=10, activation='relu', solver='adam', alpha=0.0001, batch_size='auto')

        features = self.GetFeaturesSVM(feature_ids)
        #parameters = [
        #            {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['l2'], 'loss': ['hinge', 'squared_hinge']},
        #            #{'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['l1'], 'loss': ['squared_hinge'], 'dual': [False]}
        #        ]
        #final_classifier = GridSearchCV(classifier, parameters, cv=5, n_jobs=7, iid='warn')

        final_features = Pipeline([
            ('features', features),
            ('selection', SelectPercentile(chi2, percentile=50)),
        ])

        clf = Pipeline([
            ('features', final_features),
            ('clf', classifier),
        ])

        clf.fit(training_data_dict, training_data_classification)
        #print(final_classifier.best_params_)
        ###############################################

        #feats = clf.named_steps['features']
        #test = feats.transform(training_data_dict)
        #print(test[0])

        ## Testing Vectorizer
        ##vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 1), tokenizer=CustomSpaceTokenizer, lowercase=True)
        #vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 1), tokenizer=CustomGATokenizer, lowercase=True)
        #test = Pipeline([
        #            ('selector', ItemSelector(key='contacted_urls_list')),
        #            ('vectorizer', vectorizer),
        #        ])
        #X = test.fit_transform(training_data_dict, training_data_classification)
        #feature_names = vectorizer.get_feature_names()
        #print(feature_names)

        return clf

    def BuildClassifierBagging(self, training_data_dict, training_data_classification, feature_ids):
        ## Build and Train Model ######################
        classifier = BaggingClassifier(base_estimator=None, n_estimators=1000, bootstrap=True, bootstrap_features=False, oob_score=False, warm_start=False, n_jobs=6, verbose=0)

        features = self.GetFeaturesSVM(feature_ids)
        #parameters = [
        #            {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['l2'], 'loss': ['hinge', 'squared_hinge']},
        #            #{'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['l1'], 'loss': ['squared_hinge'], 'dual': [False]}
        #        ]
        #final_classifier = GridSearchCV(classifier, parameters, cv=5, n_jobs=7, iid='warn')

        final_features = Pipeline([
            ('features', features),
            ('selection', SelectPercentile(chi2, percentile=50)),
        ])

        clf = Pipeline([
            ('features', final_features),
            ('clf', classifier),
        ])

        clf.fit(training_data_dict, training_data_classification)
        #print(final_classifier.best_params_)
        ###############################################

        #feats = clf.named_steps['features']
        #test = feats.transform(training_data_dict)
        #print(test[0])

        ## Testing Vectorizer
        ##vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 1), tokenizer=CustomSpaceTokenizer, lowercase=True)
        #vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 1), tokenizer=CustomGATokenizer, lowercase=True)
        #test = Pipeline([
        #            ('selector', ItemSelector(key='contacted_urls_list')),
        #            ('vectorizer', vectorizer),
        #        ])
        #X = test.fit_transform(training_data_dict, training_data_classification)
        #feature_names = vectorizer.get_feature_names()
        #print(feature_names)

        return clf

    def GetFeaturesNB(self, feature_ids):
        features = []

        for id in feature_ids:
            # Static
            if id == Feature.EMBEDDED_DOMAINS_LIST:
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 1), tokenizer=CustomGATokenizer, lowercase=True)
                features.append(('embedded_domains_list', Pipeline([
                    ('selector', ItemSelector(key='embedded_domains_list')),
                    ('vectorizer', vectorizer),
                ])))
            elif id == Feature.TRID:
                features.append(('trid', Pipeline([
                    ('selector', ItemSelector(key='trid')),
                    ('toarray', FunctionTransformer(self.GetGenericArray, validate = False)),
                    ('onehot', OneHotEncoder(handle_unknown='ignore')),
                ])))
            elif id == Feature.PE_RESOURCE_LIST:
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 3), tokenizer=CustomSpaceTokenizer, lowercase=True)
                features.append(('pe_resource_list', Pipeline([
                    ('selector', ItemSelector(key='pe_resource_list')),
                    ('vectorizer', vectorizer),
                ])))
            elif id == Feature.IMPORTS_LIST:
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 3), tokenizer=CustomSpaceTokenizer, lowercase=True)
                features.append(('imports_list', Pipeline([
                    ('selector', ItemSelector(key='imports_list')),
                    ('vectorizer', vectorizer),
                ])))
            elif id == Feature.CONTACTED_URLS_LIST:
                # No Bueno
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 3), tokenizer=CustomGATokenizer, lowercase=True)
                features.append(('contacted_urls_list', Pipeline([
                    ('selector', ItemSelector(key='contacted_urls_list')),
                    ('vectorizer', vectorizer),
                ])))
            # Dynamic
            elif id == Feature.SIGNATURES:
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 3), tokenizer=CustomSpaceTokenizer, lowercase=True)
                features.append(('signatures', Pipeline([
                    ('selector', ItemSelector(key='signatures')),
                    ('vectorizer', vectorizer),
                ])))
            elif id == Feature.BEHAVIOR_CALLS:
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(3, 3), tokenizer=CustomSpaceTokenizer, lowercase=True)
                features.append(('behavior_calls', Pipeline([
                    ('selector', ItemSelector(key='behavior_calls')),
                    ('vectorizer', vectorizer),
                ])))
            elif id == Feature.BEHAVIOR_DLL_LOADED:
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 3), tokenizer=CustomSpaceTokenizer, lowercase=True)
                features.append(('behavior_dll_loaded', Pipeline([
                    ('selector', ItemSelector(key='behavior_dll_loaded')),
                    ('vectorizer', vectorizer),
                ])))
            elif id == Feature.NETWORK_UDP_SRC:
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(3, 3), tokenizer=CustomSpaceTokenizer, lowercase=True)
                features.append(('network_udp_src', Pipeline([
                    ('selector', ItemSelector(key='network_udp_src')),
                    ('vectorizer', vectorizer),
                ])))
            elif id == Feature.NETWORK_UDP_DST:
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(3, 3), tokenizer=CustomSpaceTokenizer, lowercase=True)
                features.append(('network_udp_dst', Pipeline([
                    ('selector', ItemSelector(key='network_udp_dst')),
                    ('vectorizer', vectorizer),
                ])))
            elif id == Feature.NETWORK_HTTP:
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 3), tokenizer=CustomSpaceTokenizer, lowercase=True)
                features.append(('network_http', Pipeline([
                    ('selector', ItemSelector(key='network_http')),
                    ('vectorizer', vectorizer),
                ])))
            elif id == Feature.NETWORK_HOSTS:
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 3), tokenizer=CustomSpaceTokenizer, lowercase=True)
                features.append(('network_hosts', Pipeline([
                    ('selector', ItemSelector(key='network_hosts')),
                    ('vectorizer', vectorizer),
                ])))
            elif id == Feature.STRINGS: ## 1,2,3-Gram Better for NB, 3-Gram Better for SVM
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 3), tokenizer=CustomSpaceTokenizer, lowercase=True)
                features.append(('strings', Pipeline([
                    ('selector', ItemSelector(key='strings')),
                    ('vectorizer', vectorizer),
                ])))
        return FeatureUnion(features)

    def GetFeaturesSVM(self, feature_ids):
        features = []

        for id in feature_ids:
            # Static
            if id == Feature.EMBEDDED_DOMAINS_LIST:
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 1), tokenizer=CustomGATokenizer, lowercase=True)
                features.append(('embedded_domains_list', Pipeline([
                    ('selector', ItemSelector(key='embedded_domains_list')),
                    ('vectorizer', vectorizer),
                    ('tfidf', TfidfTransformer(use_idf=False)),
                ])))
            elif id == Feature.TRID:
                features.append(('trid', Pipeline([
                    ('selector', ItemSelector(key='trid')),
                    ('toarray', FunctionTransformer(self.GetGenericArray, validate = False)),
                    ('onehot', OneHotEncoder(handle_unknown='ignore')),
                ])))
            elif id == Feature.PE_RESOURCE_LIST:
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 3), tokenizer=CustomSpaceTokenizer, lowercase=True)
                features.append(('pe_resource_list', Pipeline([
                    ('selector', ItemSelector(key='pe_resource_list')),
                    ('vectorizer', vectorizer),
                    ('tfidf', TfidfTransformer(use_idf=False)),
                ])))
            elif id == Feature.IMPORTS_LIST:
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 3), tokenizer=CustomSpaceTokenizer, lowercase=True)
                features.append(('imports_list', Pipeline([
                    ('selector', ItemSelector(key='imports_list')),
                    ('vectorizer', vectorizer),
                    ('tfidf', TfidfTransformer(use_idf=False)),
                ])))
            elif id == Feature.CONTACTED_URLS_LIST:
                # No Bueno
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 3), tokenizer=CustomGATokenizer, lowercase=True)
                features.append(('contacted_urls_list', Pipeline([
                    ('selector', ItemSelector(key='contacted_urls_list')),
                    ('vectorizer', vectorizer),
                    ('tfidf', TfidfTransformer(use_idf=False)),
                ])))
            # Dynamic
            elif id == Feature.SIGNATURES:
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 3), tokenizer=CustomSpaceTokenizer, lowercase=True)
                features.append(('signatures', Pipeline([
                    ('selector', ItemSelector(key='signatures')),
                    ('vectorizer', vectorizer),
                    ('tfidf', TfidfTransformer(use_idf=False)),
                ])))
            elif id == Feature.BEHAVIOR_CALLS:
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(3, 3), tokenizer=CustomSpaceTokenizer, lowercase=True)
                features.append(('behavior_calls', Pipeline([
                    ('selector', ItemSelector(key='behavior_calls')),
                    ('vectorizer', vectorizer),
                    ('tfidf', TfidfTransformer(use_idf=False)),
                ])))
            elif id == Feature.BEHAVIOR_DLL_LOADED:
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 3), tokenizer=CustomSpaceTokenizer, lowercase=True)
                features.append(('behavior_dll_loaded', Pipeline([
                    ('selector', ItemSelector(key='behavior_dll_loaded')),
                    ('vectorizer', vectorizer),
                    ('tfidf', TfidfTransformer(use_idf=False)),
                ])))
            elif id == Feature.NETWORK_UDP_SRC:
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(3, 3), tokenizer=CustomSpaceTokenizer, lowercase=True)
                features.append(('network_udp_src', Pipeline([
                    ('selector', ItemSelector(key='network_udp_src')),
                    ('vectorizer', vectorizer),
                    ('tfidf', TfidfTransformer(use_idf=False)),
                ])))
            elif id == Feature.NETWORK_UDP_DST:
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(3, 3), tokenizer=CustomSpaceTokenizer, lowercase=True)
                features.append(('network_udp_dst', Pipeline([
                    ('selector', ItemSelector(key='network_udp_dst')),
                    ('vectorizer', vectorizer),
                    ('tfidf', TfidfTransformer(use_idf=False)),
                ])))
            elif id == Feature.NETWORK_HTTP: ##
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 3), tokenizer=CustomSpaceTokenizer, lowercase=True)
                features.append(('network_http', Pipeline([
                    ('selector', ItemSelector(key='network_http')),
                    ('vectorizer', vectorizer),
                    ('tfidf', TfidfTransformer(use_idf=False)),
                ])))
            elif id == Feature.NETWORK_HOSTS:
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 3), tokenizer=CustomSpaceTokenizer, lowercase=True)
                features.append(('network_hosts', Pipeline([
                    ('selector', ItemSelector(key='network_hosts')),
                    ('vectorizer', vectorizer),
                    ('tfidf', TfidfTransformer(use_idf=False)),
                ])))
            elif id == Feature.STRINGS: ##
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 3), tokenizer=CustomSpaceTokenizer, lowercase=True)
                features.append(('strings', Pipeline([
                    ('selector', ItemSelector(key='strings')),
                    ('vectorizer', vectorizer),
                    ('tfidf', TfidfTransformer(use_idf=False)),
                ])))
        return FeatureUnion(features)

    def GetGenericArray(self, x):
        return np.array([t for t in x]).reshape(-1, 1)

    def GetMultipleGenericArray(self, x):
        return x