import numpy as np
from enum import Enum
from sklearn.preprocessing import FunctionTransformer
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import Binarizer

from sklearn.feature_extraction.text import CountVectorizer

from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import LinearSVC

from sklearn.pipeline import Pipeline, FeatureUnion

from Classes.ItemSelector import ItemSelector

class Feature(Enum):
    EMBEDDED_DOMAINS_LIST = 1
    TRID = 2
    PE_RESOURCE_LIST = 3
    IMPORTS_LIST = 4
    CONTACTED_URLS_LIST = 5
    BEHAVIOR_CALLS = 101
    NETWORK_UDP_SRC = 102
    NETWORK_UDP_DST = 103

def CustomSpaceTokenizer(doc):
    token = doc.split(' ')
    if '' in token:
        token.remove('')
    return token

class Classifier(object):

    def BuildClassifierNB(self, training_data_dict, training_data_classification, feature_ids):
        ## Build and Train Model ######################
        classifier = MultinomialNB()

        features = self.GetFeatures(feature_ids)

        text_clf = Pipeline([
            ('features', features),
            ('clf', classifier)
        ])

        text_clf.fit(training_data_dict, training_data_classification)
        ###############################################

        #feats = text_clf.named_steps['features']
        #test = feats.transform(training_data_dict)
        #print(test[0])

        ## Testing Vectorizer
        #vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 1), tokenizer=CustomSpaceTokenizer, lowercase=True)
        #test = Pipeline([
        #            ('selector', ItemSelector(key='network_udp_src')),
        #            ('vectorizer', vectorizer),
        #        ])
        #X = test.fit_transform(training_data_dict, training_data_classification)
        #feature_names = vectorizer.get_feature_names()
        #print(feature_names)

        return text_clf

    def GetFeatures(self, feature_ids):
        features = []

        for id in feature_ids:
            if id == Feature.EMBEDDED_DOMAINS_LIST:
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 1), tokenizer=lambda x: x.split('``'), lowercase=True)
                features.append(('embedded_domains_list', Pipeline([
                    ('selector', ItemSelector(key='embedded_domains_list')),
                    ('vectorizer', vectorizer),
                ])))
            elif id == Feature.TRID:
                features.append(('trid', Pipeline([
                    ('selector', ItemSelector(key='trid')),
                    ('toarray', FunctionTransformer(self.GetGenericArray, validate = False)),
                    ('onehot', OneHotEncoder(handle_unknown='ignore')),
                ])))
            elif id == Feature.PE_RESOURCE_LIST:
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 3), tokenizer=CustomSpaceTokenizer, lowercase=True)
                features.append(('pe_resource_list', Pipeline([
                    ('selector', ItemSelector(key='pe_resource_list')),
                    ('vectorizer', vectorizer),
                ])))
            elif id == Feature.IMPORTS_LIST:
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 1), tokenizer=CustomSpaceTokenizer, lowercase=True)
                features.append(('imports_list', Pipeline([
                    ('selector', ItemSelector(key='imports_list')),
                    ('vectorizer', vectorizer),
                ])))
            elif id == Feature.CONTACTED_URLS_LIST:
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 1), tokenizer=lambda x: x.split('``'), lowercase=True)
                features.append(('contacted_urls_list', Pipeline([
                    ('selector', ItemSelector(key='contacted_urls_list')),
                    ('vectorizer', vectorizer),
                ])))
            elif id == Feature.BEHAVIOR_CALLS:
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(2, 2), tokenizer=CustomSpaceTokenizer, lowercase=True)
                features.append(('behavior_calls', Pipeline([
                    ('selector', ItemSelector(key='behavior_calls')),
                    ('vectorizer', vectorizer),
                ])))
            elif id == Feature.NETWORK_UDP_SRC:
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 1), tokenizer=CustomSpaceTokenizer, lowercase=True)
                features.append(('network_udp_src', Pipeline([
                    ('selector', ItemSelector(key='network_udp_src')),
                    ('vectorizer', vectorizer),
                    #('binarizer', Binarizer()),
                ])))
            elif id == Feature.NETWORK_UDP_DST:
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(3, 3), tokenizer=CustomSpaceTokenizer, lowercase=True)
                features.append(('network_udp_dst', Pipeline([
                    ('selector', ItemSelector(key='network_udp_dst')),
                    ('vectorizer', vectorizer),
                    #('binarizer', Binarizer()),
                ])))
        return FeatureUnion(features)

    def GetGenericArray(self, x):
        return np.array([t for t in x]).reshape(-1, 1)

    def GetMultipleGenericArray(self, x):
        return x