import numpy as np
from enum import Enum
from sklearn.preprocessing import FunctionTransformer
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder

from sklearn.feature_extraction.text import CountVectorizer

from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import LinearSVC

from sklearn.pipeline import Pipeline, FeatureUnion

from Classes.ItemSelector import ItemSelector

class Feature(Enum):
    TRID = 1
    PE_RESOURCE_LIST = 2
    IMPORTS_LIST = 3

class Classifier(object):

    def BuildClassifierNB(self, training_data_dict, training_data_classification, feature_ids):
        ## Build and Train Model ######################
        classifier = MultinomialNB()

        features = self.GetFeatures(feature_ids)

        text_clf = Pipeline([
            ('features', features),
            ('clf', classifier)
        ])

        text_clf.fit(training_data_dict, training_data_classification)
        ###############################################

        #feats = text_clf.named_steps['features']
        #test = feats.transform(training_data_dict)
        #print(test[0])

        return text_clf

    def GetFeatures(self, feature_ids):
        features = []

        for id in feature_ids:
            if id == Feature.TRID:
                features.append(('trid', Pipeline([
                    ('selector', ItemSelector(key='trid')),
                    ('toarray', FunctionTransformer(self.GetGenericArray, validate = False)),
                    ('onehot', OneHotEncoder(handle_unknown='ignore')),
                ])))
            elif id == Feature.PE_RESOURCE_LIST:
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 3), tokenizer=lambda x: x.split(' '), lowercase=True)
                features.append(('pe_resource_list', Pipeline([
                    ('selector', ItemSelector(key='pe_resource_list')),
                    ('vectorizer', vectorizer),
                ])))
            elif id == Feature.IMPORTS_LIST:
                vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 1), tokenizer=lambda x: x.split(' '), lowercase=True)
                features.append(('imports_list', Pipeline([
                    ('selector', ItemSelector(key='imports_list')),
                    ('vectorizer', vectorizer),
                ])))

        #('behavior_calls', Pipeline([
        #    ('selector', ItemSelector(key='behavior_calls')),
        #    ('vectorizer', vectorizer1),
        #])),
        #('network_udp_src', Pipeline([
        #    ('selector', ItemSelector(key='network_udp_src')),
        #    ('vectorizer', vectorizer2),
        #])),
        #('network_udp_dst', Pipeline([
        #    ('selector', ItemSelector(key='network_udp_dst')),
        #    ('vectorizer', vectorizer3),
        #])),

        return FeatureUnion(features)

    def GetGenericArray(self, x):
        return np.array([t for t in x]).reshape(-1, 1)

    def GetMultipleGenericArray(self, x):
        return x