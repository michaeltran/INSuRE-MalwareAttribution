import argparse
import pandas as pd
import time
import numpy as np
from sklearn.model_selection import cross_val_score, KFold
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

from Classifier.Classifier import Classifier, Feature

import multiprocessing as mp

clf_obj = Classifier()

def main():
    start = time.time()

    ## Get Command-line Arguments #################
    parser = argparse.ArgumentParser()
    parser.add_argument('-d', '--data', default='../../data', help='')
    opts = parser.parse_args()
    ###############################################

    dynamic_training_data_dict = LoadDataDynamic(opts.data, 'dynamic_train_data.csv')
    dynamic_testing_data_dict = LoadDataDynamic(opts.data, 'dynamic_test_data.csv')
    dynamic_validation_data_dict = LoadDataDynamic(opts.data, 'dynamic_validation_data.csv')

    # Merge Train/Test/Val Together
    dynamic_data_dict = {}
    for key in dynamic_training_data_dict:
        dynamic_data_dict[key] = dynamic_training_data_dict[key] + dynamic_testing_data_dict[key] + dynamic_validation_data_dict[key]

    FeatureTesting(dynamic_data_dict)

    print(len(dynamic_training_data_dict['classification']))
    print(len(dynamic_testing_data_dict['classification']))

    static_training_data_dict = LoadDataStatic(opts.data, 'static_train_data.csv')
    static_testing_data_dict = LoadDataStatic(opts.data, 'static_test_data.csv')


    # BAGGING
    dynamic_features = [Feature.TRID, Feature.PE_RESOURCE_LIST, Feature.EMBEDDED_DOMAINS_LIST, Feature.IMPORTS_LIST, Feature.CONTACTED_URLS_LIST,
                        Feature.SIGNATURES, Feature.BEHAVIOR_CALLS, Feature.BEHAVIOR_DLL_LOADED, Feature.NETWORK_HTTP, Feature.NETWORK_HOSTS, Feature.STRINGS
                        ]
    print('## Bagging Testing ##')
    nb_clf = clf_obj.BuildClassifierBagging(dynamic_training_data_dict, dynamic_training_data_dict['classification'], dynamic_features)
    nb_predictions = nb_clf.predict(dynamic_testing_data_dict)
    print("Bagging Accuracy: %0.3f" % (accuracy_score(dynamic_testing_data_dict['classification'], nb_predictions)))

    # DYNAMIC
    dynamic_features = [Feature.TRID, Feature.PE_RESOURCE_LIST, Feature.EMBEDDED_DOMAINS_LIST, Feature.IMPORTS_LIST, Feature.CONTACTED_URLS_LIST,
                        Feature.SIGNATURES, Feature.BEHAVIOR_CALLS, Feature.BEHAVIOR_DLL_LOADED, Feature.NETWORK_HTTP, Feature.NETWORK_HOSTS, Feature.STRINGS
                        ]
    print('## Dynamic Testing ##')
    nb_clf = clf_obj.BuildClassifierNB(dynamic_training_data_dict, dynamic_training_data_dict['classification'], dynamic_features)
    nb_predictions = nb_clf.predict(dynamic_testing_data_dict)
    print("NB Accuracy: %0.3f" % (accuracy_score(dynamic_testing_data_dict['classification'], nb_predictions)))

    svm_clf = clf_obj.BuildClassifierSVM(dynamic_training_data_dict, dynamic_training_data_dict['classification'], dynamic_features)
    svm_predictions = svm_clf.predict(dynamic_testing_data_dict)
    print("SVM Accuracy: %0.3f" % (accuracy_score(dynamic_testing_data_dict['classification'], svm_predictions)))

    print("")

    # STATIC
    static_features = [Feature.TRID, Feature.PE_RESOURCE_LIST, Feature.EMBEDDED_DOMAINS_LIST, Feature.IMPORTS_LIST, Feature.CONTACTED_URLS_LIST]
    print('## Static Testing ##')
    nb_clf = clf_obj.BuildClassifierNB(static_training_data_dict, static_training_data_dict['classification'], static_features)
    nb_predictions = nb_clf.predict(static_testing_data_dict)
    print("NB Accuracy: %0.3f" % (accuracy_score(static_testing_data_dict['classification'], nb_predictions)))

    svm_clf = clf_obj.BuildClassifierSVM(static_training_data_dict, static_training_data_dict['classification'], static_features)
    svm_predictions = svm_clf.predict(static_testing_data_dict)
    print("SVM Accuracy: %0.3f" % (accuracy_score(static_testing_data_dict['classification'], svm_predictions)))

    end = time.time()
    print("Time Run = %fs" % (end - start))

def FeatureTesting(data):
    feature_list = [
        Feature.TRID, Feature.PE_RESOURCE_LIST, Feature.EMBEDDED_DOMAINS_LIST, Feature.IMPORTS_LIST, Feature.CONTACTED_URLS_LIST,
        Feature.SIGNATURES, Feature.BEHAVIOR_CALLS, Feature.BEHAVIOR_DLL_LOADED, Feature.NETWORK_HTTP, Feature.NETWORK_HOSTS, Feature.STRINGS
    ]

    print('All Features Included')

    start = time.time()
    CrossValidationTest(data, feature_list)
    end = time.time()
    print("Execution Time = %fs" % (end - start))
    print()

    #clf = clf_obj.BuildClassifierSVM(data, data['classification'], feature_list)
    #clf_classifier = clf.named_steps['clf']
    #clf_feats = clf.named_steps['features']
    #X = clf_feats.fit_transform(data, data['classification'])

    #start = time.time()
    #cv_scores = cross_val_score(clf_classifier, X, data['classification'], cv=10, scoring='accuracy', n_jobs=4)
    #end = time.time()
    #print("Execution Time = %fs" % (end - start))
    #print("Cross Validation Accuracy: %0.4f (+/- %0.2f)" % (cv_scores.mean(), cv_scores.std()))
    #print()

    for i in range(len(feature_list)):
        features = feature_list.copy()
        print('Leaving-out Feature: %s' % (features[i].name))
        features.pop(i)

        start = time.time()
        CrossValidationTest(data, features)
        end = time.time()
        print("Execution Time = %fs" % (end - start))
        print()

        #X = clf_feats.fit_transform(data, data['classification'])

        #start = time.time()
        #cv_scores = cross_val_score(clf_classifier, X, data['classification'], cv=10, scoring='accuracy', n_jobs=4)
        #end = time.time()
        #print("Execution Time = %fs" % (end - start))
        #print("Cross Validation Accuracy: %0.4f (+/- %0.2f)" % (cv_scores.mean(), cv_scores.std()))
        #print()
    return

def CrossValidationTest(X, feature_list):
    kf = KFold(n_splits=10)

    cv_scores = []

    # Setup Parallelization
    pool = mp.Pool(int(mp.cpu_count() / 2))
    def CollectResults(result):
        cv_scores.append(result)

    for train_index, test_index in kf.split(X['index']):
        X_train = {}
        for key in X:
            X_train[key] = [X[key][i] for i in train_index]
        Y_test = {}
        for key in X:
            Y_test[key] = [X[key][i] for i in test_index]

        # Asynchronous Call
        pool.apply_async(DoCVSplitTest, args=(X_train, Y_test, feature_list), callback=CollectResults)
        #clf = clf_obj.BuildClassifierSVM(X_train, X_train['classification'], feature_list)
        #predictions = clf.predict(Y_test)
        #cv_scores.append(accuracy_score(Y_test['classification'], predictions))

    # End Parallelization
    print('Waiting for all async calls to finish...')
    pool.close()
    pool.join()

    cv_scores = np.array(cv_scores)
    print("Cross Validation Accuracy: %0.4f (+/- %0.2f)" % (cv_scores.mean(), cv_scores.std()))

def DoCVSplitTest(X_train, Y_test, feature_list):
    clf = clf_obj.BuildClassifierSVM(X_train, X_train['classification'], feature_list)
    predictions = clf.predict(Y_test)
    return accuracy_score(Y_test['classification'], predictions)

def LoadDataStatic(data_folder_path, file_name):
    data_dict = {}
    data_dict['index'] = []
    data_dict['classification'] = []
    data_dict['embedded_domains_list'] = []
    data_dict['trid'] = []
    data_dict['pe_resource_list'] = []
    data_dict['imports_list'] = []
    data_dict['contacted_urls_list'] = []

    df = pd.read_csv(data_folder_path + '/' + file_name)
    for i in range(len(df['hash'])):
        embedded_domains_list = df['embedded_domains_list'][i]
        if embedded_domains_list != embedded_domains_list:
            embedded_domains_list = ''
        pe_resource_list = df['pe_resource_list'][i]
        if pe_resource_list != pe_resource_list:
            pe_resource_list = ''
        imports_list = df['imports_list'][i]
        if imports_list != imports_list:
            imports_list = ''
        contacted_urls_list = df['contacted_urls_list'][i]
        if contacted_urls_list != contacted_urls_list:
            contacted_urls_list = ''

        data_dict['index'].append(i)
        data_dict['classification'].append(df['classification'][i])
        data_dict['embedded_domains_list'].append(embedded_domains_list)
        data_dict['trid'].append(df['trid'][i])
        data_dict['pe_resource_list'].append(pe_resource_list)
        data_dict['imports_list'].append(imports_list)
        data_dict['contacted_urls_list'].append(contacted_urls_list)

    return data_dict

def LoadDataDynamic(data_folder_path, file_name):
    data_dict = {}
    data_dict['index'] = []
    data_dict['classification'] = []

    data_dict['signatures'] = []
    data_dict['behavior_calls'] = []
    data_dict['behavior_dll_loaded'] = []
    data_dict['network_udp_src'] = []
    data_dict['network_udp_dst'] = []
    data_dict['network_http'] = []
    data_dict['network_hosts'] = []
    data_dict['strings'] = []

    data_dict['embedded_domains_list'] = []
    data_dict['trid'] = []
    data_dict['pe_resource_list'] = []
    data_dict['imports_list'] = []
    data_dict['contacted_urls_list'] = []

    df = pd.read_csv(data_folder_path + '/' + file_name)
    for i in range(len(df['hash'])):
        signatures = df['signatures'][i]
        if signatures != signatures:
            signatures = ''
        behavior_calls = df['behavior_calls'][i]
        if behavior_calls != behavior_calls:
            behavior_calls = ''
        behavior_dll_loaded = df['behavior_dll_loaded'][i]
        if behavior_dll_loaded != behavior_dll_loaded:
            behavior_dll_loaded = ''
        network_udp_src = df['network_udp_src'][i]
        if network_udp_src != network_udp_src:
            network_udp_src = ''
        network_udp_dst = df['network_udp_dst'][i]
        if network_udp_dst != network_udp_dst:
            network_udp_dst = ''
        network_http = df['network_http'][i]
        if network_http != network_http:
            network_http = ''
        network_hosts = df['network_hosts'][i]
        if network_hosts != network_hosts:
            network_hosts = ''
        strings = df['strings'][i]
        if strings != strings:
            strings = ''

        embedded_domains_list = df['embedded_domains_list'][i]
        if embedded_domains_list != embedded_domains_list:
            embedded_domains_list = ''
        pe_resource_list = df['pe_resource_list'][i]
        if pe_resource_list != pe_resource_list:
            pe_resource_list = ''
        imports_list = df['imports_list'][i]
        if imports_list != imports_list:
            imports_list = ''
        contacted_urls_list = df['contacted_urls_list'][i]
        if contacted_urls_list != contacted_urls_list:
            contacted_urls_list = ''

        data_dict['index'].append(i)
        data_dict['classification'].append(df['classification'][i])

        data_dict['signatures'].append(signatures)
        data_dict['behavior_calls'].append(behavior_calls)
        data_dict['behavior_dll_loaded'].append(behavior_dll_loaded)
        data_dict['network_udp_src'].append(network_udp_src)
        data_dict['network_udp_dst'].append(network_udp_dst)
        data_dict['network_http'].append(network_http)
        data_dict['network_hosts'].append(network_http)
        data_dict['strings'].append(strings)

        data_dict['embedded_domains_list'].append(embedded_domains_list)
        data_dict['trid'].append(df['trid'][i])
        data_dict['pe_resource_list'].append(pe_resource_list)
        data_dict['imports_list'].append(imports_list)
        data_dict['contacted_urls_list'].append(contacted_urls_list)

    return data_dict

if __name__ == '__main__':
    main()